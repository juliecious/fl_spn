{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-28T11:36:21.293714Z",
     "start_time": "2025-08-28T11:36:21.291415Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from simple_einet.einet import Einet, EinetConfig\n",
    "from simple_einet.layers.distributions.piecewise_linear import PiecewiseLinear\n",
    "from simple_einet.dist import DataType, Domain"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Import, Preprocess and Split the Dataset \n",
    "\n",
    "Traditional non-federated learning mode"
   ],
   "id": "32fde84733b0454"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T13:34:44.667443Z",
     "start_time": "2025-08-28T13:34:44.582326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = fetch_openml('adult', version=2, as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "df = df.replace('?', np.nan)\n",
    "df_clean = df.dropna()\n",
    "X = df_clean.drop('class', axis=1)\n",
    "y = df_clean['class']\n"
   ],
   "id": "85c54b159b178d05",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T13:34:46.177918Z",
     "start_time": "2025-08-28T13:34:46.174531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical feat: ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"Categorical feat: ({len(categorical_features)}): {categorical_features}\")"
   ],
   "id": "be3d3b302abe2e80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical feat: (6): ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "Categorical feat: (8): ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:35:18.748634Z",
     "start_time": "2025-08-28T11:35:18.661004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', LabelEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n",
    "X_numeric = StandardScaler().fit_transform(X[numeric_features])\n",
    "X_numeric_df = pd.DataFrame(X_numeric, columns=numeric_features, index=X.index)\n",
    "\n",
    "X_categorical_encoded = pd.DataFrame(index=X.index)\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_categorical_encoded[col] = le.fit_transform(X[col].astype(str))\n",
    "    \n",
    "X_processed = pd.concat([X_numeric_df, X_categorical_encoded], axis=1)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "print(f\"X shape after preprocessed: {X_processed.shape}\")\n",
    "print(f\"Target unique: {np.unique(y_encoded)}\")"
   ],
   "id": "f743203e4dff30ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after preprocessed: (45222, 14)\n",
      "Target unique: [0 1]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:35:42.249416Z",
     "start_time": "2025-08-28T11:35:42.228661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed.values, y_encoded, test_size=0.33, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "y_train_tensor = torch.tensor(y_train).long()\n",
    "y_test_tensor = torch.tensor(y_test).long()\n",
    "\n",
    "print(f\"X Train shape: {X_train_tensor.shape}\")\n",
    "print(f\"X Test shape: {X_test_tensor.shape}\")"
   ],
   "id": "5dcbb518a0c83617",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train shape: torch.Size([30298, 14])\n",
      "X Test shape: torch.Size([14924, 14])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Construct the domain used for Einet with Piecewise Distribution",
   "id": "dc321f3d87cb6ca8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:37:24.022536Z",
     "start_time": "2025-08-28T11:37:24.018251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "domains = []\n",
    "all_features = numeric_features + categorical_features\n",
    "\n",
    "for i, feature in enumerate(all_features):\n",
    "    if feature in numeric_features:\n",
    "        # 數值型特徵使用連續域\n",
    "        domains.append(Domain(data_type=DataType.CONTINUOUS))\n",
    "    else:\n",
    "        # 類別型特徵使用離散域\n",
    "        # 獲取唯一值作為離散值域\n",
    "        unique_values = sorted(X_processed[feature].unique())\n",
    "        domains.append(Domain(data_type=DataType.DISCRETE, values=unique_values))\n",
    "\n",
    "print(f\"Defined {len(domains)} feature domains.\")"
   ],
   "id": "3410b08c067a53d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 14 feature domains.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Configure Einet",
   "id": "cf6c7182cb8ce924"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:44:38.442259Z",
     "start_time": "2025-08-28T11:44:38.437176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 重塑訓練資料為 EiNet 所需的格式 [batch_size, channels, features]\n",
    "# 這裡 channels=1，因為我們沒有多通道資料\n",
    "X_train_reshaped = X_train_tensor.unsqueeze(1)  # [batch_size, 1, features]\n",
    "\n",
    "# 配置 EiNet 使用 PiecewiseLinear 分布\n",
    "config = EinetConfig(\n",
    "    num_features=X_train_tensor.shape[1],  # 特徵數量\n",
    "    depth=2,  # 網路深度\n",
    "    num_sums=10,  # sum nodes 數量\n",
    "    num_leaves=10,  # leaf nodes 數量  \n",
    "    num_repetitions=5,  # 重複數量\n",
    "    num_classes=2,  # 分類類別數（<=50K, >50K）\n",
    "    leaf_type=PiecewiseLinear,  # 使用 PiecewiseLinear 分布\n",
    "    leaf_kwargs={'alpha': 0.1},  # Laplace 平滑參數\n",
    "    dropout=0.0\n",
    ")\n",
    "\n",
    "# 初始化模型\n",
    "model = Einet(config)\n",
    "print(f\"模型參數數量: {sum(p.numel() for p in model.parameters())}\")"
   ],
   "id": "ab20438e31edb91f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型參數數量: 1119\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:44:50.238767Z",
     "start_time": "2025-08-28T11:44:49.631879Z"
    }
   },
   "cell_type": "code",
   "source": "model.leaf.base_leaf.initialize(X_train_reshaped, domains)",
   "id": "382ca27e7db14426",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing PiecewiseLinear Leaf Layer: 100%|██████████| 5/5 [00:00<00:00,  8.41it/s]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train the model",
   "id": "27a7b48db94d88f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:00.385991Z",
     "start_time": "2025-08-28T19:03:55.902262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        predictions = outputs.argmax(-1) \n",
    "        correct = (predictions == y).sum()\n",
    "        total = y.shape[0]\n",
    "        return 100. * correct / total\n",
    "\n",
    "\n",
    "def f1(model, X, y, num_classes=None):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        predictions = outputs.argmax(-1)\n",
    "        # 假設 y 和 predictions 為 1D tensor\n",
    "        if num_classes is None:\n",
    "            num_classes = int(torch.max(y).item()) + 1\n",
    "        f1_scores = []\n",
    "        for c in range(num_classes):\n",
    "            tp = ((predictions == c) & (y == c)).sum().item()\n",
    "            fp = ((predictions == c) & (y != c)).sum().item()\n",
    "            fn = ((predictions != c) & (y == c)).sum().item()\n",
    "            if tp + fp + fn == 0:\n",
    "                f1 = 0.0  # 防止0除\n",
    "            else:\n",
    "                precision = tp / (tp + fp) if (tp + fp) != 0 else 0.0\n",
    "                recall = tp / (tp + fn) if (tp + fn) != 0 else 0.0\n",
    "                if precision + recall == 0:\n",
    "                    f1 = 0.0\n",
    "                else:\n",
    "                    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            f1_scores.append(f1)\n",
    "        # 取 macro-average F1\n",
    "        return 100. * sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "\n",
    "X_test_reshaped = X_test_tensor.unsqueeze(1)\n",
    "\n",
    "num_epochs = 10\n",
    "print(\"Start training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    log_likelihoods = model(X_train_reshaped)\n",
    "    loss = cross_entropy(log_likelihoods, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        acc_train = accuracy(model, X_train_reshaped, y_train_tensor)\n",
    "        acc_test = accuracy(model, X_test_reshaped, y_test_tensor)\n",
    "        print(f\"Epoch: {epoch+1:2d}, Loss: {loss.item():.4f}, \"\n",
    "              f\"Train Acc: {acc_train:.2f}%, Test Acc: {acc_test:.2f}%\")\n",
    "\n",
    "print(\"Finished training！\")"
   ],
   "id": "8f2638bd26999126",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch:  5, Loss: 0.4959, Train Acc: 64.07%, Test Acc: 62.89%\n",
      "Epoch: 10, Loss: 0.4865, Train Acc: 64.86%, Test Acc: 64.05%\n",
      "Finished training！\n"
     ]
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Going Federated by constructing a Data Partitioner for \n",
    "- Horizontal \n",
    "- Vertical\n",
    "- Hybrid "
   ],
   "id": "6cfaacb3075bcab7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T13:33:55.616795Z",
     "start_time": "2025-08-28T13:33:55.612297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from typing import Dict, List"
   ],
   "id": "ef09254762fcf4b",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T15:11:22.506041Z",
     "start_time": "2025-08-28T15:11:22.485120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 健壯版聯邦學習資料分割器（與之前相同）\n",
    "class FederatedDataPartitionerRobust:\n",
    "    \"\"\"健壯版聯邦學習資料分割器\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, feature_names, numeric_features, categorical_features):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.feature_names = feature_names\n",
    "        self.numeric_features = numeric_features\n",
    "        self.categorical_features = categorical_features\n",
    "        \n",
    "    def horizontal_partition(self, num_clients: int = 3, random_state: int = 42) -> Dict:\n",
    "        \"\"\"水平分割：相同特徵，不同樣本\"\"\"\n",
    "        print(f\"🔄 執行水平分割，分成 {num_clients} 個客戶端...\")\n",
    "        \n",
    "        np.random.seed(random_state)\n",
    "        n_samples = len(self.X)\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        clients = {}\n",
    "        samples_per_client = n_samples // num_clients\n",
    "        \n",
    "        for i in range(num_clients):\n",
    "            start_idx = i * samples_per_client\n",
    "            if i == num_clients - 1:\n",
    "                end_idx = n_samples\n",
    "            else:\n",
    "                end_idx = (i + 1) * samples_per_client\n",
    "                \n",
    "            client_indices = indices[start_idx:end_idx]\n",
    "            \n",
    "            clients[f'client_{i}'] = {\n",
    "                'X': self.X[client_indices],\n",
    "                'y': self.y[client_indices],\n",
    "                'features': self.feature_names,\n",
    "                'numeric_features': self.numeric_features,\n",
    "                'categorical_features': self.categorical_features,\n",
    "                'n_samples': len(client_indices),\n",
    "                'n_features': len(self.feature_names),\n",
    "                'sample_indices': client_indices,\n",
    "                'feature_indices': list(range(len(self.feature_names))),\n",
    "                'feature_overlap': self.feature_names  # 完全重疊\n",
    "            }\n",
    "            \n",
    "            print(f\"  客戶端 {i}: {len(client_indices)} 樣本, {len(self.feature_names)} 特徵\")\n",
    "            \n",
    "        return {\n",
    "            'type': 'horizontal',\n",
    "            'clients': clients,\n",
    "            'total_samples': n_samples,\n",
    "            'total_features': len(self.feature_names)\n",
    "        }\n",
    "    \n",
    "    def vertical_partition(self, num_clients: int = 3, random_state: int = 42) -> Dict:\n",
    "        \"\"\"垂直分割：相同樣本，不同特徵\"\"\"\n",
    "        print(f\"🔄 執行垂直分割，分成 {num_clients} 個客戶端...\")\n",
    "        \n",
    "        random.seed(random_state)\n",
    "        all_features = self.feature_names.copy()\n",
    "        random.shuffle(all_features)\n",
    "        \n",
    "        features_per_client = len(all_features) // num_clients\n",
    "        clients = {}\n",
    "        \n",
    "        for i in range(num_clients):\n",
    "            start_idx = i * features_per_client\n",
    "            if i == num_clients - 1:\n",
    "                end_idx = len(all_features)\n",
    "            else:\n",
    "                end_idx = (i + 1) * features_per_client\n",
    "                \n",
    "            client_features = all_features[start_idx:end_idx]\n",
    "            client_numeric = [f for f in client_features if f in self.numeric_features]\n",
    "            client_categorical = [f for f in client_features if f in self.categorical_features]\n",
    "            \n",
    "            feature_indices = [self.feature_names.index(f) for f in client_features]\n",
    "            \n",
    "            clients[f'client_{i}'] = {\n",
    "                'X': self.X[:, feature_indices],\n",
    "                'y': self.y,\n",
    "                'features': client_features,\n",
    "                'numeric_features': client_numeric,\n",
    "                'categorical_features': client_categorical,\n",
    "                'n_samples': len(self.X),\n",
    "                'n_features': len(client_features),\n",
    "                'feature_indices': feature_indices,\n",
    "                'sample_indices': list(range(len(self.X))),\n",
    "                'feature_overlap': []  # 垂直分割無特徵重疊\n",
    "            }\n",
    "            \n",
    "            print(f\"  客戶端 {i}: {len(self.X)} 樣本, {len(client_features)} 特徵\")\n",
    "            \n",
    "        return {\n",
    "            'type': 'vertical', \n",
    "            'clients': clients,\n",
    "            'total_samples': len(self.X),\n",
    "            'total_features': len(self.feature_names)\n",
    "        }\n",
    "    \n",
    "    def hybrid_partition(self, num_clients: int = 4, \n",
    "                        sample_overlap_ratio: float = 0.3,\n",
    "                        feature_overlap_ratio: float = 0.2,\n",
    "                        random_state: int = 42) -> Dict:\n",
    "        \"\"\"健壯版混合分割：正確實現樣本和特徵重疊\"\"\"\n",
    "        print(f\"🔄 執行健壯版混合分割，分成 {num_clients} 個客戶端...\")\n",
    "        print(f\"  樣本重疊比例: {sample_overlap_ratio:.1%}\")\n",
    "        print(f\"  特徵重疊比例: {feature_overlap_ratio:.1%}\")\n",
    "        \n",
    "        np.random.seed(random_state)\n",
    "        random.seed(random_state)\n",
    "        \n",
    "        n_samples = len(self.X)\n",
    "        n_features = len(self.feature_names)\n",
    "        \n",
    "        # 樣本分配策略\n",
    "        base_samples_per_client = max(1, int(n_samples * 0.5 / num_clients))\n",
    "        overlap_sample_count = int(n_samples * sample_overlap_ratio)\n",
    "        all_sample_indices = np.arange(n_samples, dtype=int)\n",
    "        np.random.shuffle(all_sample_indices)\n",
    "        \n",
    "        base_samples_end = min(base_samples_per_client * num_clients, n_samples)\n",
    "        base_sample_indices = all_sample_indices[:base_samples_end]\n",
    "        \n",
    "        if overlap_sample_count > 0 and base_samples_end < n_samples:\n",
    "            remaining_samples = all_sample_indices[base_samples_end:]\n",
    "            overlap_sample_indices = remaining_samples[:min(overlap_sample_count, len(remaining_samples))]\n",
    "        else:\n",
    "            overlap_sample_indices = np.array([], dtype=int)\n",
    "        \n",
    "        # 特徵分配策略\n",
    "        base_features_per_client = max(1, int(n_features * 0.6 / num_clients))\n",
    "        overlap_feature_count = int(n_features * feature_overlap_ratio)\n",
    "        all_feature_indices = np.arange(n_features, dtype=int)\n",
    "        np.random.shuffle(all_feature_indices)\n",
    "        \n",
    "        base_features_end = min(base_features_per_client * num_clients, n_features)\n",
    "        base_feature_indices = all_feature_indices[:base_features_end]\n",
    "        \n",
    "        if overlap_feature_count > 0 and base_features_end < n_features:\n",
    "            remaining_features = all_feature_indices[base_features_end:]\n",
    "            overlap_feature_indices = remaining_features[:min(overlap_feature_count, len(remaining_features))]\n",
    "        else:\n",
    "            overlap_feature_indices = np.array([], dtype=int)\n",
    "        \n",
    "        print(f\"  基礎樣本: {len(base_sample_indices)} 個，重疊樣本池: {len(overlap_sample_indices)} 個\")\n",
    "        print(f\"  基礎特徵: {len(base_feature_indices)} 個，重疊特徵池: {len(overlap_feature_indices)} 個\")\n",
    "        \n",
    "        # 為每個客戶端分配資料\n",
    "        clients = {}\n",
    "        \n",
    "        for i in range(num_clients):\n",
    "            # 樣本分配\n",
    "            client_base_start = i * base_samples_per_client\n",
    "            client_base_end = min((i + 1) * base_samples_per_client, len(base_sample_indices))\n",
    "            client_base_samples = base_sample_indices[client_base_start:client_base_end]\n",
    "            \n",
    "            if len(overlap_sample_indices) > 0:\n",
    "                overlap_sample_size = min(len(overlap_sample_indices), len(client_base_samples) // 2)\n",
    "                if overlap_sample_size > 0:\n",
    "                    client_overlap_samples = np.random.choice(\n",
    "                        overlap_sample_indices, size=overlap_sample_size, replace=False\n",
    "                    )\n",
    "                else:\n",
    "                    client_overlap_samples = np.array([], dtype=int)\n",
    "            else:\n",
    "                client_overlap_samples = np.array([], dtype=int)\n",
    "            \n",
    "            if len(client_overlap_samples) > 0:\n",
    "                client_sample_indices = np.concatenate([client_base_samples, client_overlap_samples])\n",
    "            else:\n",
    "                client_sample_indices = client_base_samples.copy()\n",
    "            client_sample_indices = np.unique(client_sample_indices)\n",
    "            \n",
    "            # 特徵分配\n",
    "            client_base_feat_start = i * base_features_per_client\n",
    "            client_base_feat_end = min((i + 1) * base_features_per_client, len(base_feature_indices))\n",
    "            client_base_features = base_feature_indices[client_base_feat_start:client_base_feat_end]\n",
    "            \n",
    "            if len(overlap_feature_indices) > 0:\n",
    "                guaranteed_overlap_size = max(1, len(overlap_feature_indices) // 2)\n",
    "                guaranteed_overlap_features = overlap_feature_indices[:guaranteed_overlap_size]\n",
    "                client_overlap_features = guaranteed_overlap_features\n",
    "            else:\n",
    "                client_overlap_features = np.array([], dtype=int)\n",
    "            \n",
    "            if len(client_overlap_features) > 0:\n",
    "                client_feature_indices = np.concatenate([client_base_features, client_overlap_features])\n",
    "            else:\n",
    "                client_feature_indices = client_base_features.copy()\n",
    "            client_feature_indices = np.unique(client_feature_indices.astype(int))\n",
    "            \n",
    "            # 確保至少有一個特徵\n",
    "            if len(client_feature_indices) == 0:\n",
    "                client_feature_indices = np.array([0], dtype=int)\n",
    "            \n",
    "            # 獲取特徵名稱\n",
    "            client_features = [self.feature_names[idx] for idx in client_feature_indices]\n",
    "            client_numeric = [f for f in client_features if f in self.numeric_features]\n",
    "            client_categorical = [f for f in client_features if f in self.categorical_features]\n",
    "            \n",
    "            # 計算重疊特徵\n",
    "            overlap_features_names = []\n",
    "            if len(client_overlap_features) > 0:\n",
    "                overlap_features_names = [self.feature_names[idx] for idx in client_overlap_features]\n",
    "            \n",
    "            clients[f'client_{i}'] = {\n",
    "                'X': self.X[np.ix_(client_sample_indices, client_feature_indices)],\n",
    "                'y': self.y[client_sample_indices],\n",
    "                'features': client_features,\n",
    "                'numeric_features': client_numeric,\n",
    "                'categorical_features': client_categorical,\n",
    "                'n_samples': len(client_sample_indices),\n",
    "                'n_features': len(client_features),\n",
    "                'feature_indices': client_feature_indices,\n",
    "                'sample_indices': client_sample_indices,\n",
    "                'base_sample_count': len(client_base_samples),\n",
    "                'overlap_sample_count': len(client_overlap_samples),\n",
    "                'base_feature_count': len(client_base_features),\n",
    "                'overlap_feature_count': len(client_overlap_features),\n",
    "                'feature_overlap': overlap_features_names\n",
    "            }\n",
    "            \n",
    "            print(f\"  客戶端 {i}: {len(client_sample_indices)} 樣本 × {len(client_features)} 特徵\")\n",
    "        \n",
    "        return {\n",
    "            'type': 'hybrid_robust',\n",
    "            'clients': clients,\n",
    "            'total_samples': n_samples,\n",
    "            'total_features': n_features,\n",
    "            'sample_overlap_ratio': sample_overlap_ratio,\n",
    "            'feature_overlap_ratio': feature_overlap_ratio\n",
    "        }\n"
   ],
   "id": "d4de123a4fe1bd89",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:14:26.446939Z",
     "start_time": "2025-08-28T19:14:26.428777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "\n",
    "\n",
    "def _accuracy(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        predictions = outputs.argmax(-1) \n",
    "        correct = (predictions == y).sum()\n",
    "        total = y.shape[0]\n",
    "        return 100. * correct / total\n",
    "\n",
    "\n",
    "def _f1_score(model, X, y, num_classes=None):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        predictions = outputs.argmax(-1)\n",
    "        # 假設 y 和 predictions 為 1D tensor\n",
    "        if num_classes is None:\n",
    "            num_classes = int(torch.max(y).item()) + 1\n",
    "        f1_scores = []\n",
    "        for c in range(num_classes):\n",
    "            tp = ((predictions == c) & (y == c)).sum().item()\n",
    "            fp = ((predictions == c) & (y != c)).sum().item()\n",
    "            fn = ((predictions != c) & (y == c)).sum().item()\n",
    "            if tp + fp + fn == 0:\n",
    "                f1 = 0.0  # 防止0除\n",
    "            else:\n",
    "                precision = tp / (tp + fp) if (tp + fp) != 0 else 0.0\n",
    "                recall = tp / (tp + fn) if (tp + fn) != 0 else 0.0\n",
    "                if precision + recall == 0:\n",
    "                    f1 = 0.0\n",
    "                else:\n",
    "                    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            f1_scores.append(f1)\n",
    "        # 取 macro-average F1\n",
    "        return 100. * sum(f1_scores) / len(f1_scores)\n",
    "    \n",
    "# 基於 simple-einet API 的聯邦學習訓練器\n",
    "class FederatedEiNetTrainer:\n",
    "    \"\"\"\n",
    "    聯邦 EiNet 訓練器 - 使用 simple-einet API 風格\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, partition_info: Dict):\n",
    "        self.partition_info = partition_info\n",
    "        self.client_models = {}\n",
    "        self.client_domains = {}\n",
    "        self.training_history = {}\n",
    "        \n",
    "    def create_domains(self, features: List[str], numeric_features: List[str], \n",
    "                      categorical_features: List[str], X_processed: pd.DataFrame) -> List:\n",
    "        \"\"\"為給定特徵創建 domains\"\"\"\n",
    "        domains = []\n",
    "        \n",
    "        for feature in features:\n",
    "            if feature in numeric_features:\n",
    "                if feature in X_processed.columns:\n",
    "                    min_val = float(X_processed[feature].min())\n",
    "                    max_val = float(X_processed[feature].max())\n",
    "                    domains.append(Domain.continuous_range(min_val, max_val))\n",
    "                else:\n",
    "                    # 如果特徵不在 X_processed 中，使用預設範圍\n",
    "                    domains.append(Domain.continuous_range(-3.0, 3.0))\n",
    "            else:\n",
    "                if feature in X_processed.columns:\n",
    "                    values = sorted(X_processed[feature].unique().tolist())\n",
    "                    domains.append(Domain.discrete_bins(values))\n",
    "                else:\n",
    "                    # 如果特徵不在 X_processed 中，使用預設值\n",
    "                    domains.append(Domain.discrete_bins([0, 1]))\n",
    "                \n",
    "        return domains\n",
    "    \n",
    "    def train_client(self, client_id: str, client_data: Dict, X_processed: pd.DataFrame,\n",
    "                    epochs: int = 100, verbose: bool = False) -> Dict:\n",
    "        \"\"\"訓練單個客戶端的 EiNet 模型\"\"\"\n",
    "        \n",
    "        X_client = client_data['X']\n",
    "        y_client = client_data['y']\n",
    "        \n",
    "        X_client_reshaped = X_client.unsqueeze(1)\n",
    "        \n",
    "        # 創建該客戶端特徵的 domains\n",
    "        domains = self.create_domains(\n",
    "            client_data['features'],\n",
    "            client_data['numeric_features'],\n",
    "            client_data['categorical_features'],\n",
    "            X_processed,\n",
    "        )\n",
    "        \n",
    "        num_features = client_data['n_features']\n",
    "        \n",
    "        # 動態調整模型複雜度\n",
    "        if num_features < 3:\n",
    "            depth, num_sums, num_leaves = 1, 4, 4\n",
    "        elif num_features < 6:\n",
    "            depth, num_sums, num_leaves = 1, 8, 8  \n",
    "        else:\n",
    "            depth, num_sums, num_leaves = 2, 12, 12\n",
    "            \n",
    "        config = EinetConfig(\n",
    "            num_features=num_features,\n",
    "            depth=depth,\n",
    "            num_sums=num_sums,\n",
    "            num_leaves=num_leaves,\n",
    "            num_repetitions=3,\n",
    "            num_classes=2,\n",
    "            leaf_type=PiecewiseLinear,\n",
    "            leaf_kwargs={'alpha': 0.1},\n",
    "            dropout=0.0\n",
    "        )\n",
    "        \n",
    "        model = Einet(config)\n",
    "        model.leaf.base_leaf.initialize(X_client_reshaped, domains)\n",
    "        \n",
    "        cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"    📊 模型配置: depth={depth}, sums={num_sums}, leaves={num_leaves}\")\n",
    "            print(f\"    🔧 特徵域: {len(domains)} 個 domain\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            ll = model(X_client_reshaped)\n",
    "            loss = cross_entropy(ll, y_client)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                acc_train = _accuracy(model, X_client_reshaped, y_client)\n",
    "                f1_train = _f1_score(model, X_client_reshaped, y_client)\n",
    "                print(f\"Epoch: {epoch+1:2d}, Loss: {loss.item():.4f}, \"\n",
    "                      f\"Train Acc: {acc_train:.2f}%, F1: {f1_train:.2f}%\")\n",
    "            \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        train_accuracy = _accuracy(model, X_client_reshaped, y_client)\n",
    "        train_f1 = _f1_score(model, X_client_reshaped, y_client)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"    ✅ 訓練準確率: {train_accuracy:.3f}\")\n",
    "            print(f\"    📈 訓練 F1 分數: {train_f1:.3f}\")\n",
    "            print(f\"    ⏱️  訓練時間: {training_time:.3f} 秒\")\n",
    "        \n",
    "        return {\n",
    "            'client_id': client_id,\n",
    "            'model': model,\n",
    "            'domains': domains,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'train_f1': train_f1,\n",
    "            'training_time': training_time,\n",
    "            'config': config\n",
    "        }\n",
    "    \n",
    "    def train_federated_learning(self, X_processed: pd.DataFrame, epochs: int = 100, \n",
    "                               verbose: bool = True) -> Dict:\n",
    "        \"\"\"執行聯邦學習訓練\"\"\"\n",
    "        \n",
    "        print(f\"\\n🚀 開始 {self.partition_info['type']} 聯邦學習訓練...\")\n",
    "        print(f\"訓練參數: epochs={epochs}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        \n",
    "        # 訓練每個客戶端\n",
    "        for client_id, client_data in self.partition_info['clients'].items():\n",
    "            if verbose:\n",
    "                print(f\"\\n📍 訓練 {client_id}...\")\n",
    "                print(f\"   資料規模: {client_data['n_samples']} 樣本 × {client_data['n_features']} 特徵\")\n",
    "                if client_data.get('feature_overlap'):\n",
    "                    print(f\"   🔗 重疊特徵: {len(client_data['feature_overlap'])} 個 {client_data['feature_overlap']}\")\n",
    "                \n",
    "            # 訓練客戶端模型\n",
    "            client_result = self.train_client(\n",
    "                client_id, client_data, X_processed, epochs, verbose=verbose\n",
    "            )\n",
    "            \n",
    "            # 儲存結果\n",
    "            self.client_models[client_id] = client_result['model']\n",
    "            self.client_domains[client_id] = client_result['domains']\n",
    "            \n",
    "            results[client_id] = {\n",
    "                'train_accuracy': client_result['train_accuracy'],\n",
    "                'train_f1': client_result['train_f1'],\n",
    "                'training_time': client_result['training_time'],\n",
    "                'n_samples': client_data['n_samples'],\n",
    "                'n_features': client_data['n_features'],\n",
    "                'feature_overlap': client_data.get('feature_overlap', []),\n",
    "                'config': client_result['config'],\n",
    "                'domains_count': len(client_result['domains'])\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   🎯 {client_id} 訓練完成\")\n",
    "        \n",
    "        # 計算整體統計\n",
    "        total_samples = sum(r['n_samples'] for r in results.values())\n",
    "        weighted_accuracy = sum(\n",
    "            r['train_accuracy'] * r['n_samples'] for r in results.values()\n",
    "        ) / total_samples\n",
    "        \n",
    "        weighted_f1 = sum(\n",
    "            r['train_f1'] * r['n_samples'] for r in results.values()\n",
    "        ) / total_samples\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n📊 {self.partition_info['type']} 聯邦學習完成！\")\n",
    "            print(f\"   ⏱️  總訓練時間: {total_time:.2f} 秒\")\n",
    "            print(f\"   🎯 加權平均訓練準確率: {weighted_accuracy:.3f}\")\n",
    "            print(f\"   📈 加權平均 F1 分數: {weighted_f1:.3f}\")\n",
    "            print(f\"   🏢 參與客戶端: {len(results)} 個\")\n",
    "            print(f\"   📊 總樣本數: {total_samples}\")\n",
    "        \n",
    "        return {\n",
    "            'type': self.partition_info['type'],\n",
    "            'client_results': results,\n",
    "            'weighted_accuracy': weighted_accuracy,\n",
    "            'weighted_f1': weighted_f1,\n",
    "            'total_training_time': total_time,\n",
    "            'total_samples': total_samples,\n",
    "            'num_clients': len(results)\n",
    "        }\n",
    "    \n",
    "    def evaluate_on_test(self, X_test, y_test, test_feature_names) -> Dict:\n",
    "        \"\"\"在測試集上評估聯邦模型\"\"\"\n",
    "        \n",
    "        print(f\"\\n📋 在測試集上評估聯邦 EiNet 模型...\")\n",
    "        \n",
    "        client_evaluations = {}\n",
    "        predictions_ensemble = []\n",
    "        probabilities_ensemble = []\n",
    "        \n",
    "        for client_id, model in self.client_models.items():\n",
    "            client_data = self.partition_info['clients'][client_id]\n",
    "            \n",
    "            # 找到客戶端特徵在測試集中的對應索引\n",
    "            client_feature_indices = []\n",
    "            for feature in client_data['features']:\n",
    "                if feature in test_feature_names:\n",
    "                    client_feature_indices.append(test_feature_names.index(feature))\n",
    "            \n",
    "            if len(client_feature_indices) == 0:\n",
    "                print(f\"   ⚠️  {client_id}: 沒有對應的測試特徵\")\n",
    "                continue\n",
    "                \n",
    "            # 提取客戶端對應的測試特徵\n",
    "            X_test_client = X_test[:, client_feature_indices]\n",
    "            \n",
    "            # 按照 simple-einet 風格 reshape\n",
    "            X_test_client_reshaped = torch.tensor(X_test_client).unsqueeze(1)\n",
    "            \n",
    "            # 預測\n",
    "            try:\n",
    "                acc = accuracy(model, X_test_client_reshaped, y_test)\n",
    "                fscore = f1(model, X_test_client_reshaped, torch.from_numpy(y_test))\n",
    "                \n",
    "                probs = torch.exp(model(X_test_client_reshaped))\n",
    "                predictions = probs.argmax(dim=-1)  \n",
    "                \n",
    "                client_evaluations[client_id] = {\n",
    "                    'accuracy': acc,\n",
    "                    'f1_score': fscore,\n",
    "                    'n_test_features': len(client_feature_indices),\n",
    "                    'predictions': predictions,\n",
    "                }\n",
    "                \n",
    "                predictions_ensemble.append(predictions.detach().numpy())\n",
    "                probabilities_ensemble.append(probs.detach().numpy())\n",
    "                \n",
    "                print(f\"   {client_id}: 準確率 {acc:.3f}, F1 {fscore:.3f} ({len(client_feature_indices)} 特徵)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ {client_id}: 評估失敗 - {str(e)}\")\n",
    "        \n",
    "        # 集成預測（簡單投票和平均機率）\n",
    "        if predictions_ensemble and probabilities_ensemble:\n",
    "            # 投票集成\n",
    "            predictions_array = np.array(predictions_ensemble)\n",
    "            ensemble_predictions_vote = np.apply_along_axis(\n",
    "                lambda x: np.bincount(x).argmax(), axis=0, arr=predictions_array\n",
    "            )\n",
    "            \n",
    "            # 機率平均集成\n",
    "            ensemble_probabilities = np.mean(probabilities_ensemble, axis=0)\n",
    "            ensemble_predictions_prob = np.argmax(ensemble_probabilities, axis=1)\n",
    "            \n",
    "            vote_accuracy = accuracy_score(y_test, ensemble_predictions_vote)\n",
    "            vote_f1 = f1_score(y_test, ensemble_predictions_vote, average='weighted')\n",
    "            # \n",
    "            prob_accuracy = accuracy_score(y_test, ensemble_predictions_prob)\n",
    "            prob_f1 = f1_score(y_test, ensemble_predictions_prob, average='weighted')\n",
    "            \n",
    "            # 選擇更好的集成方法\n",
    "            if prob_accuracy >= vote_accuracy:\n",
    "                ensemble_accuracy = prob_accuracy\n",
    "                ensemble_f1 = prob_f1\n",
    "                ensemble_predictions = ensemble_predictions_prob\n",
    "                ensemble_method = \"機率平均\"\n",
    "            else:\n",
    "                ensemble_accuracy = vote_accuracy\n",
    "                ensemble_f1 = vote_f1\n",
    "                ensemble_predictions = ensemble_predictions_vote\n",
    "                ensemble_method = \"投票\"\n",
    "                \n",
    "        else:\n",
    "            ensemble_accuracy = 0.0\n",
    "            ensemble_f1 = 0.0\n",
    "            ensemble_predictions = None\n",
    "            ensemble_method = \"無\"\n",
    "        \n",
    "        print(f\"\\n🎯 集成結果 ({ensemble_method}):\")\n",
    "        print(f\"   準確率: {ensemble_accuracy:.3f}\")\n",
    "        print(f\"   F1 分數: {ensemble_f1:.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'client_evaluations': client_evaluations,\n",
    "            'ensemble_accuracy': ensemble_accuracy,\n",
    "            'ensemble_f1': ensemble_f1,\n",
    "            'ensemble_predictions': ensemble_predictions,\n",
    "            'ensemble_method': ensemble_method\n",
    "        }\n"
   ],
   "id": "37b367d3a1b8bdcb",
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:14:26.684958Z",
     "start_time": "2025-08-28T19:14:26.682945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "partitioner = FederatedDataPartitionerRobust(\n",
    "    X=X_train_tensor, \n",
    "    y=y_train_tensor,\n",
    "    feature_names=X_processed.columns.tolist(),\n",
    "    numeric_features=numeric_features,\n",
    "    categorical_features=categorical_features\n",
    ")"
   ],
   "id": "3e7199f1de972d22",
   "outputs": [],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:14:32.010435Z",
     "start_time": "2025-08-28T19:14:26.899739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 實驗 1: 水平聯邦學習 - Simple-EiNet 風格\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔵 實驗 1: 水平聯邦學習 (使用 Simple-EiNet API)\")\n",
    "print(\"相同特徵，不同樣本\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "horizontal_partition = partitioner.horizontal_partition(num_clients=3, random_state=42)\n",
    "horizontal_trainer = FederatedEiNetTrainer(horizontal_partition)\n",
    "horizontal_results = horizontal_trainer.train_federated_learning(\n",
    "    X_processed, epochs=5, verbose=True\n",
    ")\n",
    "\n",
    "# 在測試集上評估\n",
    "horizontal_eval = horizontal_trainer.evaluate_on_test(\n",
    "    X_test, y_test, X_processed.columns.tolist()\n",
    ")"
   ],
   "id": "4128c3494ca9045",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔵 實驗 1: 水平聯邦學習 (使用 Simple-EiNet API)\n",
      "相同特徵，不同樣本\n",
      "============================================================\n",
      "🔄 執行水平分割，分成 3 個客戶端...\n",
      "  客戶端 0: 10099 樣本, 14 特徵\n",
      "  客戶端 1: 10099 樣本, 14 特徵\n",
      "  客戶端 2: 10100 樣本, 14 特徵\n",
      "\n",
      "🚀 開始 horizontal 聯邦學習訓練...\n",
      "訓練參數: epochs=5\n",
      "\n",
      "📍 訓練 client_0...\n",
      "   資料規模: 10099 樣本 × 14 特徵\n",
      "   🔗 重疊特徵: 14 個 ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing PiecewiseLinear Leaf Layer: 100%|██████████| 3/3 [00:00<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    📊 模型配置: depth=2, sums=12, leaves=12\n",
      "    🔧 特徵域: 14 個 domain\n",
      "Epoch:  5, Loss: 0.7386, Train Acc: 39.94%, F1: 39.77%\n",
      "    ✅ 訓練準確率: 39.945\n",
      "    📈 訓練 F1 分數: 39.771\n",
      "    ⏱️  訓練時間: 1.039 秒\n",
      "   🎯 client_0 訓練完成\n",
      "\n",
      "📍 訓練 client_1...\n",
      "   資料規模: 10099 樣本 × 14 特徵\n",
      "   🔗 重疊特徵: 14 個 ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing PiecewiseLinear Leaf Layer: 100%|██████████| 3/3 [00:00<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    📊 模型配置: depth=2, sums=12, leaves=12\n",
      "    🔧 特徵域: 14 個 domain\n",
      "Epoch:  5, Loss: 0.7369, Train Acc: 33.70%, F1: 33.70%\n",
      "    ✅ 訓練準確率: 33.696\n",
      "    📈 訓練 F1 分數: 33.696\n",
      "    ⏱️  訓練時間: 0.764 秒\n",
      "   🎯 client_1 訓練完成\n",
      "\n",
      "📍 訓練 client_2...\n",
      "   資料規模: 10100 樣本 × 14 特徵\n",
      "   🔗 重疊特徵: 14 個 ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing PiecewiseLinear Leaf Layer: 100%|██████████| 3/3 [00:00<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    📊 模型配置: depth=2, sums=12, leaves=12\n",
      "    🔧 特徵域: 14 個 domain\n",
      "Epoch:  5, Loss: 0.6639, Train Acc: 72.44%, F1: 56.13%\n",
      "    ✅ 訓練準確率: 72.436\n",
      "    📈 訓練 F1 分數: 56.126\n",
      "    ⏱️  訓練時間: 0.767 秒\n",
      "   🎯 client_2 訓練完成\n",
      "\n",
      "📊 horizontal 聯邦學習完成！\n",
      "   ⏱️  總訓練時間: 3.91 秒\n",
      "   🎯 加權平均訓練準確率: 48.693\n",
      "   📈 加權平均 F1 分數: 43.198\n",
      "   🏢 參與客戶端: 3 個\n",
      "   📊 總樣本數: 30298\n",
      "\n",
      "📋 在測試集上評估聯邦 EiNet 模型...\n",
      "   client_0: 準確率 46.187, F1 45.285 (14 特徵)\n",
      "   client_1: 準確率 32.511, F1 32.490 (14 特徵)\n",
      "   client_2: 準確率 73.935, F1 57.164 (14 特徵)\n",
      "\n",
      "🎯 集成結果 (投票):\n",
      "   準確率: 0.518\n",
      "   F1 分數: 0.551\n"
     ]
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:14:32.012703Z",
     "start_time": "2025-08-28T19:14:32.011487Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "333830b854d0cdb1",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "506e7d9d88ed2a5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
